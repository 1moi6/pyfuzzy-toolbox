"""
Exemplo 14: Wang-Mendel para ClassificaÃ§Ã£o Iris - Duas Abordagens

Este exemplo demonstra duas formas de usar Wang-Mendel para classificaÃ§Ã£o multi-classe:

1. ABORDAGEM 1 (Recomendada): 1 saÃ­da com 3 classes
   - Mais simples e direto
   - WangMendel cria automaticamente

2. ABORDAGEM 2 (One-vs-All): 3 saÃ­das binÃ¡rias (uma por classe)
   - Mais flexÃ­vel para problemas complexos
   - Usa WangMendelFIS com MIMO
   - DecisÃ£o final por argmax()
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import numpy as np
import fuzzy_systems as fs



def gerar_dados_iris_sintetico():
    """
    Gera dados sintÃ©ticos inspirados no dataset Iris.

    Retorna:
        X: Features (n_amostras, 4) - comprimento_sepala, largura_sepala, comprimento_petala, largura_petala
        y: Classes (n_amostras,) - 0=setosa, 1=versicolor, 2=virginica
    """
    np.random.seed(42)

    # Classe 0: Iris Setosa (pequenas)
    n_samples = 30
    setosa = np.random.randn(n_samples, 4) * 0.3 + np.array([5.0, 3.5, 1.5, 0.3])

    # Classe 1: Iris Versicolor (mÃ©dias)
    versicolor = np.random.randn(n_samples, 4) * 0.4 + np.array([6.0, 2.8, 4.5, 1.4])

    # Classe 2: Iris Virginica (grandes)
    virginica = np.random.randn(n_samples, 4) * 0.5 + np.array([6.5, 3.0, 5.5, 2.0])

    X = np.vstack([setosa, versicolor, virginica])
    y = np.array([0]*n_samples + [1]*n_samples + [2]*n_samples)

    # Embaralhar
    indices = np.random.permutation(len(X))
    X = X[indices]
    y = y[indices]

    return X, y


def abordagem_1_saida_unica():
    """
    ABORDAGEM 1: Uma saÃ­da com 3 classes (0, 1, 2)

    Vantagens:
    - Simples de implementar
    - WangMendel cuida de tudo automaticamente
    - Menos regras geradas

    Desvantagens:
    - Menos controle sobre as partiÃ§Ãµes
    """
    print("=" * 70)
    print("ABORDAGEM 1: UMA SAÃDA COM 3 CLASSES")
    print("=" * 70)
    print()

    # 1. Gerar dados
    print("1. GERANDO DADOS IRIS")
    print("-" * 70)
    X, y = gerar_dados_iris_sintetico()

    print(f"   Amostras: {len(X)}")
    print(f"   Features: {X.shape[1]}")
    print(f"   Classes: {np.unique(y)}")
    print(f"   DistribuiÃ§Ã£o: {[np.sum(y==i) for i in range(3)]}")
    print()

    # 2. Treinar classificador Wang-Mendel
    print("2. TREINANDO WANG-MENDEL")
    print("-" * 70)

    wm = fs.learning.WangMendelClassification(
        X_train=X,
        y_train=y,
        n_partitions=3,  # 3 partiÃ§Ãµes por feature
        input_names=['comp_sepala', 'larg_sepala', 'comp_petala', 'larg_petala'],
        output_name='especie',
        classification=True,
        output_labels=['setosa', 'versicolor', 'virginica']
    )

    system = wm.fit(verbose=False)

    print(f"   âœ… Sistema treinado com {len(system.rule_base.rules)} regras")
    print()

    # 3. Fazer prediÃ§Ãµes
    print("3. TESTANDO CLASSIFICADOR")
    print("-" * 70)

    # Casos de teste
    X_test = np.array([
        [5.0, 3.5, 1.5, 0.3],   # Deve ser setosa
        [6.0, 2.8, 4.5, 1.4],   # Deve ser versicolor
        [6.5, 3.0, 5.5, 2.0],   # Deve ser virginica
    ])

    y_pred = wm.predict(X_test)
    labels = ['setosa', 'versicolor', 'virginica']

    print("\n   PrediÃ§Ãµes:")
    for i in range(len(X_test)):
        print(f"   Amostra {i+1}: {X_test[i]}")
        print(f"              â†’ Classe: {labels[y_pred[i]]}")
        print()

    # 4. AcurÃ¡cia no treino
    y_train_pred = wm.predict(X)
    accuracy = np.mean(y_train_pred == y) * 100

    print(f"   AcurÃ¡cia no treino: {accuracy:.1f}%")
    print()

    # 5. Mostrar algumas regras
    print("4. EXEMPLOS DE REGRAS GERADAS")
    print("-" * 70)
    system.print_rules(style='if-then', show_stats=False)

    return wm, system


def abordagem_2_one_vs_all():
    """
    ABORDAGEM 2: TrÃªs saÃ­das binÃ¡rias (one-vs-all)

    Vantagens:
    - Total controle sobre cada classificador binÃ¡rio
    - Pode ajustar partiÃ§Ãµes diferentes para cada classe
    - Ãštil quando classes sÃ£o muito desbalanceadas

    Desvantagens:
    - Mais complexo de implementar
    - Mais regras no total
    - Precisa de decisÃ£o final (argmax)
    """
    print("\n" + "=" * 70)
    print("ABORDAGEM 2: TRÃŠS SAÃDAS BINÃRIAS (ONE-VS-ALL)")
    print("=" * 70)
    print()

    # 1. Gerar dados
    print("1. GERANDO DADOS")
    print("-" * 70)
    X, y = gerar_dados_iris_sintetico()

    # Converter para formato one-vs-all: [eh_setosa, eh_versicolor, eh_virginica]
    y_train_onehot = np.zeros((len(y), 3))
    for i, classe in enumerate(y):
        y_train_onehot[i, classe] = 1

    print(f"   Amostras: {len(X)}")
    print(f"   Formato de y_train: {y_train_onehot.shape}")
    print(f"   Exemplo: classe=1 (versicolor) â†’ {y_train_onehot[y==1][0]}")
    print()

    # 2. Criar sistema FIS com 3 saÃ­das
    print("2. CRIANDO SISTEMA FIS COM 3 SAÃDAS")
    print("-" * 70)

    system = fs.MamdaniSystem(name="Iris One-vs-All")

    # Adicionar entradas
    input_names = ['comp_sepala', 'larg_sepala', 'comp_petala', 'larg_petala']
    universes = [
        (np.min(X[:,0]), np.max(X[:,0])),  # comprimento sÃ©pala
        (np.min(X[:,1]), np.max(X[:,1])),  # largura sÃ©pala
        (np.min(X[:,2]), np.max(X[:,2])),  # comprimento pÃ©tala
        (np.min(X[:,3]), np.max(X[:,3])),  # largura pÃ©tala
    ]

    for name, universe in zip(input_names, universes):
        system.add_input(name, universe)
        # 3 partiÃ§Ãµes por feature
        system.add_term(name, 'pequeno', 'triangular',
                       (universe[0], universe[0], (universe[0]+universe[1])/2))
        system.add_term(name, 'medio', 'triangular',
                       (universe[0], (universe[0]+universe[1])/2, universe[1]))
        system.add_term(name, 'grande', 'triangular',
                       ((universe[0]+universe[1])/2, universe[1], universe[1]))

    # Adicionar 3 saÃ­das binÃ¡rias
    output_names = ['eh_setosa', 'eh_versicolor', 'eh_virginica']
    for name in output_names:
        system.add_output(name, (0, 1))
        system.add_term(name, 'nao', 'triangular', (0,0,1.0))
        system.add_term(name, 'sim', 'triangular', (0, 1, 1.0))

    print(f"   âœ… Sistema criado:")
    print(f"      Entradas: {list(system.input_variables.keys())}")
    print(f"      SaÃ­das: {list(system.output_variables.keys())}")
    print()

    # 3. Treinar com Wang-Mendel
    print("3. GERANDO REGRAS COM WANG-MENDEL")
    print("-" * 70)

    wm = fs.learning.WangMendelClassification(
        system=system,
        X_train=X,
        y_train=y_train_onehot,
    )

    system_trained = wm.fit(verbose=False)

    print(f"   âœ… Sistema treinado com {len(system_trained.rule_base.rules)} regras")

    # Verificar se hÃ¡ regras suficientes
    if len(system_trained.rule_base.rules) == 0:
        print()
        print("   âš ï¸  ATENÃ‡ÃƒO: Nenhuma regra completa foi gerada!")
        print("   Isso acontece porque Wang-Mendel precisa que TODAS as saÃ­das")
        print("   tenham consequente para o mesmo antecedente.")
        print()
        print("   ğŸ’¡ SOLUÃ‡ÃƒO: Use a Abordagem 1 para classificaÃ§Ã£o multi-classe")
        print("   ou treine 3 classificadores binÃ¡rios separados (um por classe)")
        return None, None

    print()

    # 4. Fazer prediÃ§Ãµes e decidir classe
    print("4. TESTANDO COM DECISÃƒO ARGMAX")
    print("-" * 70)

    X_test = np.array([
        [5.0, 3.5, 1.5, 0.3],   # Setosa
        [6.0, 2.8, 4.5, 1.4],   # Versicolor
        [6.5, 3.0, 5.5, 2.0],   # Virginica
    ])

    labels = ['setosa', 'versicolor', 'virginica']

    print("\n   PrediÃ§Ãµes:")
    for i in range(len(X_test)):
        # Criar entrada
        inputs = {
            'comp_sepala': X_test[i, 0],
            'larg_sepala': X_test[i, 1],
            'comp_petala': X_test[i, 2],
            'larg_petala': X_test[i, 3]
        }

        # Obter saÃ­das
        output = system_trained.evaluate(inputs)

        # Scores para cada classe
        scores = [
            output['eh_setosa'],
            output['eh_versicolor'],
            output['eh_virginica']
        ]

        # DecisÃ£o: argmax
        classe_predita = np.argmax(scores)

        print(f"   Amostra {i+1}: {X_test[i]}")
        print(f"      Scores: setosa={scores[0]:.3f}, versicolor={scores[1]:.3f}, virginica={scores[2]:.3f}")
        print(f"      â†’ Classe: {labels[classe_predita]} (Ã­ndice {classe_predita})")
        print()

    # 5. AcurÃ¡cia no treino
    print("5. ACURÃCIA NO TREINO")
    print("-" * 70)

    y_pred = []
    for x_sample in X:
        inputs = {
            'comp_sepala': x_sample[0],
            'larg_sepala': x_sample[1],
            'comp_petala': x_sample[2],
            'larg_petala': x_sample[3]
        }
        output = system_trained.evaluate(inputs)
        scores = [output['eh_setosa'], output['eh_versicolor'], output['eh_virginica']]
        y_pred.append(np.argmax(scores))

    y_pred = np.array(y_pred)
    accuracy = np.mean(y_pred == y) * 100

    print(f"   AcurÃ¡cia: {accuracy:.1f}%")
    print()

    return wm, system_trained


def comparacao_abordagens():
    """
    Compara as duas abordagens
    """
    print("\n" + "=" * 70)
    print("COMPARAÃ‡ÃƒO DAS ABORDAGENS")
    print("=" * 70)

    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ABORDAGEM 1 vs ABORDAGEM 2                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚ ABORDAGEM 1: Uma SaÃ­da com 3 Classes                                â”‚
â”‚ âœ… Vantagens:                                                        â”‚
â”‚    â€¢ Simples de implementar                                          â”‚
â”‚    â€¢ Menos regras geradas                                            â”‚
â”‚    â€¢ DecisÃ£o automÃ¡tica (classe = round(saÃ­da))                     â”‚
â”‚    â€¢ Usa WangMendel (mais rÃ¡pido)                                   â”‚
â”‚                                                                       â”‚
â”‚ âŒ Desvantagens:                                                     â”‚
â”‚    â€¢ Menos controle sobre as partiÃ§Ãµes                               â”‚
â”‚    â€¢ Assume que classes sÃ£o "ordenadas" (0 < 1 < 2)                â”‚
â”‚                                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚ ABORDAGEM 2: TrÃªs SaÃ­das BinÃ¡rias (One-vs-All)                     â”‚
â”‚ âœ… Vantagens:                                                        â”‚
â”‚    â€¢ Total controle sobre cada classificador                         â”‚
â”‚    â€¢ Pode ajustar partiÃ§Ãµes diferentes por classe                    â”‚
â”‚    â€¢ Melhor para classes desbalanceadas                              â”‚
â”‚    â€¢ DÃ¡ "scores de confianÃ§a" para cada classe                      â”‚
â”‚    â€¢ Ãštil quando classes nÃ£o sÃ£o mutuamente exclusivas               â”‚
â”‚                                                                       â”‚
â”‚ âŒ Desvantagens:                                                     â”‚
â”‚    â€¢ Mais complexo de implementar                                    â”‚
â”‚    â€¢ 3x mais regras geradas                                          â”‚
â”‚    â€¢ Precisa decidir classe final (argmax)                           â”‚
â”‚    â€¢ Usa WangMendelFIS (precisa criar FIS primeiro)                 â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ QUANDO USAR CADA UMA:

â€¢ Use ABORDAGEM 1 quando:
  - Quer simplicidade e rapidez
  - Classes sÃ£o bem separadas
  - NÃ£o precisa de scores de confianÃ§a
  - Dataset balanceado

â€¢ Use ABORDAGEM 2 quando:
  - Precisa de controle fino sobre cada classe
  - Classes desbalanceadas (ex: 90% classe A, 5% B, 5% C)
  - Quer scores de confianÃ§a
  - Pode ter exemplos pertencentes a mÃºltiplas classes
  - ClassificaÃ§Ã£o hierÃ¡rquica

ğŸ“Š PARA O IRIS:
   Ambas funcionam bem! Recomendo ABORDAGEM 1 pela simplicidade.
   Use ABORDAGEM 2 se precisar explicar a "confianÃ§a" da prediÃ§Ã£o.
    """)


def main():
    print("\n")
    print("*" * 70)
    print(" " * 15 + "WANG-MENDEL PARA CLASSIFICAÃ‡ÃƒO IRIS")
    print(" " * 20 + "Comparando Duas Abordagens")
    print("*" * 70)

    # Abordagem 1
    # wm1, sys1 = abordagem_1_saida_unica()

    input("\n\nPressione Enter para continuar para a Abordagem 2...")

    # Abordagem 2
    wm2, sys2 = abordagem_2_one_vs_all()

    if wm2 is not None:  # Se gerou regras
        input("\n\nPressione Enter para ver a comparaÃ§Ã£o...")
        comparacao_abordagens()
    else:
        print("\nâš ï¸  Abordagem 2 nÃ£o conseguiu gerar regras completas.")
        print("Para classificaÃ§Ã£o multi-classe, recomendamos a Abordagem 1!")

    print("\n" + "=" * 70)
    print("FIM DO EXEMPLO")
    print("=" * 70)


if __name__ == "__main__":
    main()
