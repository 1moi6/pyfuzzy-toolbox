{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/1moi6/pyfuzzy-toolbox/blob/main/notebooks_colab/Aula_4/01_anfis_iris_classificacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† ANFIS: Classifica√ß√£o de Flores Iris\n",
    "\n",
    "**Aula 4 - Minicurso de Sistemas de Infer√™ncia Fuzzy**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Objetivo\n",
    "\n",
    "Neste notebook, vamos aplicar **ANFIS (Adaptive Neuro-Fuzzy Inference System)** para classificar flores Iris.\n",
    "\n",
    "### O que √© ANFIS?\n",
    "\n",
    "ANFIS combina:\n",
    "- üß© **L√≥gica Fuzzy**: Regras interpret√°veis\n",
    "- üß† **Redes Neurais**: Aprendizado autom√°tico (backpropagation)\n",
    "\n",
    "### Vantagens sobre Wang-Mendel:\n",
    "- ‚úÖ **Refina** as fun√ß√µes de pertin√™ncia (MFs)\n",
    "- ‚úÖ **Otimiza** par√¢metros (n√£o apenas gera regras)\n",
    "- ‚úÖ **Adapta-se** aos dados via gradient descent\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Refer√™ncias\n",
    "- Jang, J. S. (1993). \"ANFIS: adaptive-network-based fuzzy inference system.\" *IEEE transactions on systems, man, and cybernetics*, 23(3), 665-685.\n",
    "- Fisher, R. A. (1936). \"The use of multiple measurements in taxonomic problems.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Instala√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyfuzzy-toolbox[ml] scikit-learn -q\n",
    "\n",
    "print('‚úÖ pyfuzzy-toolbox e scikit-learn instalados com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Importa√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import fuzzy_systems as fs\n",
    "from fuzzy_systems.learning import ANFIS\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Configura√ß√µes\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set_palette('husl')\n",
    "np.random.seed(42)\n",
    "\n",
    "print('‚úÖ Bibliotecas importadas!')\n",
    "print(f'   pyfuzzy-toolbox: {fs.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Passo 1: Carregar e Explorar Dataset Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset\n",
    "iris = load_iris()\n",
    "X_full = iris.data\n",
    "y_full = iris.target\n",
    "\n",
    "# Criar DataFrame para facilitar visualiza√ß√£o\n",
    "df = pd.DataFrame(X_full, columns=iris.feature_names)\n",
    "df['species'] = iris.target_names[y_full]\n",
    "\n",
    "print('üìä Dataset Iris carregado!')\n",
    "print(f'\\nShape: {X_full.shape}')\n",
    "print(f'\\nClasses: {iris.target_names}')\n",
    "print(f'\\nFeatures: {iris.feature_names}')\n",
    "print('\\nPrimeiras 5 amostras:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualizar Distribui√ß√£o das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribui√ß√£o das features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(iris.feature_names):\n",
    "    for species_id, species_name in enumerate(iris.target_names):\n",
    "        data = df[df['species'] == species_name][feature]\n",
    "        axes[idx].hist(data, alpha=0.6, bins=15, label=species_name)\n",
    "    \n",
    "    axes[idx].set_xlabel(feature, fontsize=11)\n",
    "    axes[idx].set_ylabel('Frequ√™ncia', fontsize=11)\n",
    "    axes[idx].set_title(f'Distribui√ß√£o: {feature}', fontsize=12, weight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Visualiza√ß√£o criada!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Passo 2: Preparar Dados - Classifica√ß√£o Bin√°ria (2 Features)\n",
    "\n",
    "Vamos come√ßar com um problema **mais simples**:\n",
    "- Usar apenas **2 features**: Petal Length e Petal Width\n",
    "- **Classifica√ß√£o bin√°ria**: Setosa vs N√£o-Setosa\n",
    "\n",
    "**Por qu√™?** Setosa √© linearmente separ√°vel das outras esp√©cies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as features da p√©tala (colunas 2 e 3)\n",
    "X_2d = X_full[:, 2:4]  # petal length e petal width\n",
    "\n",
    "# Criar labels bin√°rios: Setosa (0) vs Outras (1)\n",
    "y_binary = (y_full != 0).astype(int)  # 0 = Setosa, 1 = N√£o-Setosa\n",
    "\n",
    "print('Features selecionadas:')\n",
    "print(f'  - {iris.feature_names[2]}')\n",
    "print(f'  - {iris.feature_names[3]}')\n",
    "print(f'\\nDistribui√ß√£o das classes:')\n",
    "print(f'  Setosa:     {np.sum(y_binary == 0)} amostras')\n",
    "print(f'  N√£o-Setosa: {np.sum(y_binary == 1)} amostras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualizar Separabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar separabilidade\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = ['red', 'blue']\n",
    "labels = ['Setosa', 'N√£o-Setosa']\n",
    "\n",
    "for class_id in [0, 1]:\n",
    "    mask = y_binary == class_id\n",
    "    ax.scatter(X_2d[mask, 0], X_2d[mask, 1], \n",
    "              c=colors[class_id], label=labels[class_id],\n",
    "              s=80, alpha=0.7, edgecolors='black', linewidth=1)\n",
    "\n",
    "ax.set_xlabel(iris.feature_names[2] + ' (cm)', fontsize=13)\n",
    "ax.set_ylabel(iris.feature_names[3] + ' (cm)', fontsize=13)\n",
    "ax.set_title('Iris Dataset - 2 Features (P√©tala)', fontsize=15, weight='bold')\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Note: Setosa √© claramente separ√°vel das outras classes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Passo 3: Dividir e Normalizar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados: 70% treino, 15% valida√ß√£o, 15% teste\n",
    "X_train_2d, X_temp_2d, y_train_2d, y_temp_2d = train_test_split(\n",
    "    X_2d, y_binary, test_size=0.3, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "X_val_2d, X_test_2d, y_val_2d, y_test_2d = train_test_split(\n",
    "    X_temp_2d, y_temp_2d, test_size=0.5, random_state=42, stratify=y_temp_2d\n",
    ")\n",
    "\n",
    "print(f'Conjunto de treino:    {len(X_train_2d)} amostras')\n",
    "print(f'Conjunto de valida√ß√£o: {len(X_val_2d)} amostras')\n",
    "print(f'Conjunto de teste:     {len(X_test_2d)} amostras')\n",
    "\n",
    "# Normalizar dados\n",
    "scaler_2d = StandardScaler()\n",
    "X_train_2d_norm = scaler_2d.fit_transform(X_train_2d)\n",
    "X_val_2d_norm = scaler_2d.transform(X_val_2d)\n",
    "X_test_2d_norm = scaler_2d.transform(X_test_2d)\n",
    "\n",
    "print('\\n‚úÖ Dados normalizados!')\n",
    "print(f'\\nRanges ap√≥s normaliza√ß√£o:')\n",
    "print(f'  Feature 1: [{X_train_2d_norm[:, 0].min():.2f}, {X_train_2d_norm[:, 0].max():.2f}]')\n",
    "print(f'  Feature 2: [{X_train_2d_norm[:, 1].min():.2f}, {X_train_2d_norm[:, 1].max():.2f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Passo 4: Criar e Treinar Modelo ANFIS\n",
    "\n",
    "### Arquitetura ANFIS:\n",
    "\n",
    "- **2 entradas** (petal_length, petal_width)\n",
    "- **3 MFs** por entrada ‚Üí 3¬≤ = **9 regras**\n",
    "- **Regulariza√ß√£o L2** para evitar overfitting\n",
    "- **Learning rate**: 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar modelo ANFIS\n",
    "anfis_2d = ANFIS(\n",
    "    n_inputs=2,\n",
    "    n_mfs=3,\n",
    "    learning_rate=1e-3,\n",
    "    lambda_l2=0.01,  # Regulariza√ß√£o L2\n",
    "    classification=True\n",
    ")\n",
    "\n",
    "print('‚úÖ Modelo ANFIS criado!')\n",
    "print(f'\\nüìä Arquitetura:')\n",
    "print(f'   ‚Ä¢ Entradas: 2')\n",
    "print(f'   ‚Ä¢ MFs por entrada: 3')\n",
    "print(f'   ‚Ä¢ Total de regras: 9')\n",
    "print(f'   ‚Ä¢ Learning rate: 0.001')\n",
    "print(f'   ‚Ä¢ Regulariza√ß√£o: L2 (Œª=0.01)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Treinar ANFIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar\n",
    "print('Iniciando treinamento...\\n')\n",
    "\n",
    "anfis_2d.fit(\n",
    "    X_train_2d_norm, y_train_2d,\n",
    "    epochs=200,\n",
    "    validation_data=(X_val_2d_norm, y_val_2d),\n",
    "    early_stopping_patience=30,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('‚úÖ Treinamento conclu√≠do!')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualizar Converg√™ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar curvas de aprendizado\n",
    "history = anfis_2d.history\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(history['loss'], 'b-', linewidth=2, label='Treino', alpha=0.8)\n",
    "ax1.plot(history['val_loss'], 'r--', linewidth=2, label='Valida√ß√£o', alpha=0.8)\n",
    "ax1.set_xlabel('√âpoca', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Converg√™ncia - Loss', fontsize=14, weight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax2.plot(history['accuracy'], 'b-', linewidth=2, label='Treino', alpha=0.8)\n",
    "ax2.plot(history['val_accuracy'], 'r--', linewidth=2, label='Valida√ß√£o', alpha=0.8)\n",
    "ax2.set_xlabel('√âpoca', fontsize=12)\n",
    "ax2.set_ylabel('Acur√°cia', fontsize=12)\n",
    "ax2.set_title('Converg√™ncia - Acur√°cia', fontsize=14, weight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Curvas de aprendizado geradas!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Passo 5: Avaliar Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predi√ß√µes\n",
    "y_train_pred_2d = anfis_2d.predict(X_train_2d_norm)\n",
    "y_val_pred_2d = anfis_2d.predict(X_val_2d_norm)\n",
    "y_test_pred_2d = anfis_2d.predict(X_test_2d_norm)\n",
    "\n",
    "# Acur√°cias\n",
    "acc_train_2d = accuracy_score(y_train_2d, y_train_pred_2d)\n",
    "acc_val_2d = accuracy_score(y_val_2d, y_val_pred_2d)\n",
    "acc_test_2d = accuracy_score(y_test_2d, y_test_pred_2d)\n",
    "\n",
    "print('='*70)\n",
    "print('üìä RESULTADOS - CLASSIFICA√á√ÉO BIN√ÅRIA (2 FEATURES)')\n",
    "print('='*70)\n",
    "print(f'Acur√°cia Treino:    {acc_train_2d*100:6.2f}%')\n",
    "print(f'Acur√°cia Valida√ß√£o: {acc_val_2d*100:6.2f}%')\n",
    "print(f'Acur√°cia Teste:     {acc_test_2d*100:6.2f}%')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Matriz de Confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confus√£o\n",
    "cm_test_2d = confusion_matrix(y_test_2d, y_test_pred_2d)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm_test_2d, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Setosa', 'N√£o-Setosa'],\n",
    "            yticklabels=['Setosa', 'N√£o-Setosa'],\n",
    "            cbar_kws={'label': 'Contagem'})\n",
    "ax.set_xlabel('Predito', fontsize=13)\n",
    "ax.set_ylabel('Real', fontsize=13)\n",
    "ax.set_title(f'Matriz de Confus√£o - Teste\\nAcur√°cia: {acc_test_2d*100:.2f}%',\n",
    "            fontsize=14, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relat√≥rio detalhado\n",
    "print('\\nüìã RELAT√ìRIO DE CLASSIFICA√á√ÉO - CONJUNTO DE TESTE')\n",
    "print('='*70)\n",
    "print(classification_report(y_test_2d, y_test_pred_2d,\n",
    "                           target_names=['Setosa', 'N√£o-Setosa'],\n",
    "                           digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Visualizar Fronteira de Decis√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar grid para a superf√≠cie de decis√£o\n",
    "x1_min, x1_max = X_train_2d_norm[:, 0].min() - 0.5, X_train_2d_norm[:, 0].max() + 0.5\n",
    "x2_min, x2_max = X_train_2d_norm[:, 1].min() - 0.5, X_train_2d_norm[:, 1].max() + 0.5\n",
    "\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max, 200),\n",
    "                       np.linspace(x2_min, x2_max, 200))\n",
    "\n",
    "# Fazer predi√ß√µes no grid\n",
    "print('Gerando superf√≠cie de decis√£o...')\n",
    "Z = anfis_2d.predict(np.c_[xx1.ravel(), xx2.ravel()]).reshape(xx1.shape)\n",
    "print('Superf√≠cie gerada!')\n",
    "\n",
    "# Plotar fronteira de decis√£o\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Superf√≠cie\n",
    "contour = ax.contourf(xx1, xx2, Z, levels=[0, 0.5, 1],\n",
    "                      colors=['#ffcccc', '#ccccff'], alpha=0.6)\n",
    "\n",
    "# Contorno da fronteira\n",
    "ax.contour(xx1, xx2, Z, levels=[0.5], colors='black',\n",
    "           linewidths=3, linestyles='solid')\n",
    "\n",
    "# Pontos com indica√ß√£o de erro\n",
    "corretos = y_test_2d == y_test_pred_2d\n",
    "incorretos = ~corretos\n",
    "\n",
    "ax.scatter(X_test_2d_norm[corretos, 0], X_test_2d_norm[corretos, 1],\n",
    "           c='green', marker='o', s=100, label='Correto',\n",
    "           edgecolors='black', linewidth=1.5, alpha=0.8)\n",
    "ax.scatter(X_test_2d_norm[incorretos, 0], X_test_2d_norm[incorretos, 1],\n",
    "           c='orange', marker='X', s=150, label='Erro',\n",
    "           edgecolors='red', linewidth=2, alpha=0.9)\n",
    "\n",
    "ax.set_xlabel('Comprimento da P√©tala (normalizado)', fontsize=12)\n",
    "ax.set_ylabel('Largura da P√©tala (normalizado)', fontsize=12)\n",
    "ax.set_title(f'Fronteira de Decis√£o ANFIS\\nErros: {np.sum(incorretos)}/{len(y_test_2d)}',\n",
    "             fontsize=14, weight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Conclus√µes\n",
    "\n",
    "### ‚úÖ O que aprendemos?\n",
    "\n",
    "1. **ANFIS combina o melhor de dois mundos**:\n",
    "   - **Fuzzy**: Regras interpret√°veis\n",
    "   - **Neural**: Aprendizado autom√°tico via backpropagation\n",
    "\n",
    "2. **Vantagens sobre Wang-Mendel**:\n",
    "   - Wang-Mendel: Gera regras, MFs fixas\n",
    "   - ANFIS: **Refina** MFs e consequentes via gradient descent\n",
    "\n",
    "3. **Regulariza√ß√£o √© importante**:\n",
    "   - L2 (Ridge) evita overfitting\n",
    "   - Especialmente √∫til com poucas amostras\n",
    "\n",
    "4. **Trade-offs**:\n",
    "   - ANFIS: Mais par√¢metros, mais flex√≠vel, treino mais lento\n",
    "   - Wang-Mendel: Menos par√¢metros, mais r√°pido, menos flex√≠vel\n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ ANFIS vs Wang-Mendel\n",
    "\n",
    "| Aspecto | Wang-Mendel | ANFIS |\n",
    "|---------|-------------|-------|\n",
    "| Gera√ß√£o de regras | Autom√°tica (1 passo) | Inicializa√ß√£o + refinamento |\n",
    "| Fun√ß√µes de pertin√™ncia | Fixas | **Aprendidas** |\n",
    "| Consequentes | Fixos | **Otimizados** |\n",
    "| Tempo de treino | R√°pido | Mais lento |\n",
    "| Flexibilidade | Menor | **Maior** |\n",
    "| Interpretabilidade | Alta | Alta (se MFs n√£o mudam muito) |\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos\n",
    "\n",
    "1. **Experimentar com 4 features** (todas as vari√°veis do Iris)\n",
    "2. **Testar diferentes valores de regulariza√ß√£o** (Œª)\n",
    "3. **Comparar com outros m√©todos** (SVM, Random Forest)\n",
    "4. **Aplicar a outros datasets** de classifica√ß√£o\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Recursos\n",
    "\n",
    "- **PyPI**: https://pypi.org/project/pyfuzzy-toolbox/\n",
    "- **GitHub**: https://github.com/1moi6/pyfuzzy-toolbox\n",
    "\n",
    "### üìñ Refer√™ncias\n",
    "\n",
    "1. **Jang, J. S. (1993)**. \"ANFIS: adaptive-network-based fuzzy inference system.\" *IEEE transactions on systems, man, and cybernetics*, 23(3), 665-685.\n",
    "\n",
    "2. **Fisher, R. A. (1936)**. \"The use of multiple measurements in taxonomic problems.\" *Annals of Eugenics*, 7(2), 179-188.\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Parab√©ns! Voc√™ aplicou ANFIS para classifica√ß√£o!**\n",
    "\n",
    "*Notebook desenvolvido para o Minicurso de Sistemas de Infer√™ncia Fuzzy - Aula 4 - 2025*  \n",
    "*Usando pyfuzzy-toolbox v1.0.0*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
